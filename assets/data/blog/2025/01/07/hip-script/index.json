{"hash":"2444d141b30d78a3cbc00240cc093b1342d97959","data":{"post":{"id":"757854843a4e697a7f6d7e276735e562","title":"HipScript","description":"By chaining several compilers, you can run CUDA code in the browser!","content":"<p>By chaining <a href=\"https://github.com/CHIP-SPV/chipStar/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">chipStar</a> (a HIP and NVIDIA® CUDA® to OpenCL compiler), <a href=\"https://github.com/google/clspv/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Clspv</a> (an OpenCL to Vulkan compiler), and <a href=\"https://dawn.googlesource.com/dawn/+/refs/heads/main/src/tint/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Tint</a> (among others, a Vulkan shader to WebGPU shader compiler), you can run CUDA code in the browser!</p>\n<p><a href=\"https://hipscript.lights0123.com/\" target=\"_blank\" rel=\"noopener\" class=\"xl:col-span-3 py-3 bg-gray-600 flex justify-center items-center text-white bg-gradient-cool font-bold text-3xl\">Try it out! ↗</a></p>\n<p><a href=\"https://github.com/lights0123/hipscript/\" target=\"_blank\" rel=\"noopener\" class=\"xl:col-span-3 py-3 flex justify-center items-center text-white bg-gray-800 font-bold text-3xl\">Source on GitHub ↗</a></p>\n<div class=\"light-only\">\n<p><img class=\"g-image g-image--lazy g-image--loading\" src=\"data:image/svg+xml,%3csvg fill='none' viewBox='0 0 1555 404' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-59346f01fa87d36bcc950dc2e25ba123'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-59346f01fa87d36bcc950dc2e25ba123)' width='1555' height='404' xlink:href='data:image/svg%2bxml%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAARCAYAAABtu6qMAAAACXBIWXMAAAsTAAALEwEAmpwYAAAHu0lEQVRYw41XiY6jSBL1/39Pf0BrpV5NH1Vll8sX5jDYGLABgzE35Fu9qEqP%2b9DspBSKJI/IOF5EJhMAg1JqIP%2bV4jgegiAYfN8fNoYxOI4znM/nIUmS4XQ6/XFPXddDnudDlmVD13W/zXPseDyKHMoIw3CIokiI/ce1fd%2bLrMvlMlRV9dMc5VO/NE2Fc39ZljJHblmWjI3jeLeFdhwOBxnn%2baQJPlrf9zidTgjDUOjl5QWz2Qxt0yLLMjiOI9%2bu68lay7KwWq1gGAau1yuapkGe5zL%2b%2bvoqPAgC1HWN2%2b2GNE1Fxo8fP2Qt99i2LeS6LsZxxPF4lH2Xy0X2HQ4HrNdrLBYLWVOWpehC3biuqirsdjv4vi86sc%2b9lDOfz7HdbpEkyYfe72fQNs5zPWVNlFIKgEqSRMVxzE/VdZ0qikK5nqvmb3O1XC3VfPGmNoahZq8zGTMtU/VDr4IwUMbWUGEUKmfnKP/oK9fdqSRNZP9%2b7ynLNmXO23vq%2beVZZVmmkjhRpmkKWZalrterOh6Pcm4URWq9XivHcdTpdJLx3W6nbNuW9eScb5pGHQ4H5bqu6vtexvb7vVoul2qxWKjZbCbfT09PyvM8sbOua5HJ/u12U5N3%2byGeYwTZ9FhTNUiiFGVeYrPc4st//kJxuSFPrkLocSfVAqoDxlZBtQpDM8o36b6OrBpwjmLxPlFBYpTIi6LAv23Ul4glgsgpg6hhoyxGmgjquk7GzuczPM/D8/OzIJSo4Zp7ChCShKpuwzCiKwacghiO6eG4D7FebrFZmfB2B/j7AFvDlrFzlKCpWlRFjbps0FYdmrJFdatlrCoa1Ld36psBfTnez6GzNRGiv46z0TimEw2l42gMHcDUiKLoQ99BiNB%2bbJQRxzE2m42kE53CvVr2hBu4kYJ4AL/7ocfYjuiqHgoKTd%2bg6Rq0HzxJU%2bxcF5bjwNm5MC0b9m6Hnedha1mYLxbYbLdwXFfWuZ6HIAxxOp%2bR366CFjrM9VyJAiPDHNU1iI54dAwV5jzrBw1hDZhOp1JTGDgiV%2bc851mbSDSYdYGOYtTZ5zwdqtuEBYGHcpKK0BEcu6QZyqjB1S9RhjWqc4Py1KAr%2bg9IxQjD6CdvEzUlC5PrYbVmcSwA9TN0Z/NXxEGCrukRnSKBKA3W0WOk27b9DfJ0DqNHeBMB1PlxHQviox0stEwJFk5yElOMxDHO8%2bwJIUWv0MP0tGXZotg5OiNapojXOVL7imSb47zKxCEaWnRCXTeoWdWLAvO3Bbamhf3Bh2U7mM3fBB08nAe2bYfX%2bRzWxkZ8iuF5rpzNfGREGTE6n0rqmkT%2b6dMnmKYpKco5OktqVNPIPING4pyGNh2lU0bL4ZjmRAHPnTA/CB16jYcTOnESS6G6%2bFfkXilGX5wCl13xnhYfhzDSxtbE22KJl%2bkrXmaveHqe4sfzC96WKyxWa6zWG2yMrTjEMExcsgwYgcV8KUozcixkb29vElEqxiuO0aRuRASDQ2WpHznXPj09yVpGU9cO6kUncT1TQteP5XIp1zXPoQyiRBfSCQ%2biUBIhxs1ULDxGaIteok%2b6uAViI5cipotOkqS/QZWIsJ2dIOFPUJ69vmI1XyO/vOcuz2fk6XgqRIP5zfxm3uo5ndMcJzFo3EtdaSTTgn1GnAaz2rPROXQSHaNTgchhk1uASnABjd/v96JUUVzR1h26W486blHHndwIddK9v8NYA%2bJYipp2BtsxCMVwImOxXONtsUKW5xKZvh%2bkRiyWS7lK27rF6Xy679fVm8axaOnKT%2bjTEbriE%2baM4OONxb6%2bSukAoooO0ZWfnJEnUaZOGa6/X4Pvhv99Dw/tKHf2tb4iv%2bXIrhmu5VU4K7%2b338O0ban2PoWHAdz9Xm4Dcu9wkBvA5/V1PiNOkvstMJQjurpHkiaiCJVlvpIYBHKdZgwMDSCnkzhOB3AfUUtYM1WINhpOeixy3EPbaOyf2kTnD5XQ18OoRozyDuiRnC44HiL4XgDTcGCbLuIohe%2bF2JkePPuA6lqjK3u0t%2b5vXvXo60FoaAa5VlX//kBqrt0/PnKosL73qbi%2b6miofgOw0QmfP3%2bWcc7rYkcnMJjacPYZ/cerVdPksWoSPo8vwXFUuKYFmluL%2bXQpj56%2b7lFkN3nU4OPdwl8p%2bZ0a30l/02DS2CmpHXTKUI/ou%2bGuIOFLYtRoKJV/fMQwkr%2bSdhCj/%2b3bN0GNrmPMf8KeRY%2bFnWjR7wttl%2baCAP0vwPd5mqbSH8dRtU0r72j%2bH1yyi5rOpurLf78ow9jIG9r3fZVeUtW0jaqbWqi4FfKmL8tSlVWpqqoSzu9h5E/nKDwIAnnv53ku/wHT6fS%2bT/8D8P0fhqH8o1Av/a/Cdzy/%2bR9APbbbrdI2kCiTuvEMPUY6n8/3dY/r7zWAqcAUoMdYiL5%2b/Yrv37/LHG8Gy7SkELEan6KTRI1e5npGgvP0PvOVESHnOKPCa4195jFfcV//%2bvpTfj/%2bERLORMFjlP5futxT9%2bEp/RhpytNP5t9qAIBWKT5O0er%2bOI7SL4qi9X2/tSyrNU2zdV233Ww2rWEY7eFwaKuquu/7N6TlZlkmch3HEdm73U76HIvj%2bCdd/om4ZhgG2ReGYbvf70WWbdsiz/O8NggCoa7r2l9tJf0Pj6cVP53dkE0AAAAASUVORK5CYII=' /%3e%3c/svg%3e\" width=\"1555\" alt=\"foo\" data-srcset=\"/assets/static/hipscript.82a2fbd.25bbe5d1d695cc44a24a0a4515000949.svg 480w, /assets/static/hipscript.cbab2cf.25bbe5d1d695cc44a24a0a4515000949.svg 1024w, /assets/static/hipscript.a72e906.25bbe5d1d695cc44a24a0a4515000949.svg 1555w\" data-sizes=\"(max-width: 1555px) 100vw, 1555px\" data-src=\"/assets/static/hipscript.a72e906.25bbe5d1d695cc44a24a0a4515000949.svg\"><noscript><img class=\"g-image g-image--lazy g-image--loaded\" src=\"/assets/static/hipscript.a72e906.25bbe5d1d695cc44a24a0a4515000949.svg\" width=\"1555\" alt=\"foo\"></noscript></p>\n</div>\n<div class=\"dark-only\">\n<p><img class=\"g-image g-image--lazy g-image--loading\" src=\"data:image/svg+xml,%3csvg fill='none' viewBox='0 0 1555 404' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-b29a5aaa3afb700c1784b72fd5a80b0f'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-b29a5aaa3afb700c1784b72fd5a80b0f)' width='1555' height='404' xlink:href='data:image/svg%2bxml%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAARCAYAAABtu6qMAAAACXBIWXMAAAsTAAALEwEAmpwYAAAIzUlEQVRYw5VYWYwcZxHunWPn2rmvnumu6p57Zufc6WPn77F3ZhfjI74EcYwTx46NIjmyg7mCOYTCAzEQWZGAgCB2pMjE4CgGgWIH4kQYFCAKLyABQclDHnhEiDxECIkjavTPVtvtzSJCS%2bXp7vr7d9VXVV/Vv4IgCAIACJtdAJAFxCIAyIjYQsQKAOQQMQ0A%2bf/yTRAA4iT%2bTfQ%2bACgiYhYR84hYQESR7wcAhQ1rvQAQA4AkAIQ36BIAkEHEFCJmAEB01gBABABqtKeH3mXID6C1We7LTefJsJkRAFgAABMB9RrWAyqWEiDJ3HldQaVUx6YPUakjYhcRF1VUY2WsBFRU4whYR8AhglJXQJHKWA2WsLygoppWUKkiKqyMlSA5xo2sAkAJET3cQHqXIiC5tW0A6PE15BgHwwSAOgCEAIDbBQRWmfR8nyUAaJLjGuk86/7N9NzfhBsAHtVMSSkJMkh%2bFUvRIhTUvJzr56VsByrKQCrJLVHKDQsgDkQ5XxNEwZuTMwUR8s2snBbzcq6clTNSXs6VElIslZOzalZOY07O1nJyhutQlHNGUorFFVQy5ESDO42IMTIsShHqEDg8KBI5UKX1VQImQM6XCIA2gdYFgD45zp9HAKC6MjRP9wtuADhyMX7/65W/zN7d2TwSuqt1vHgfPBBfG%2b4drhh37DnWeDB1uH4ic6R5Mmuv2D57zfbZE9v/5lZ7/u9Te/71Lf%2bef2PrO/M3Rm8G/za1/f9atf32%2b2y/vc2elcNF86XwtLqjkJXTcQVVnr5pKqnUzKD3eJG9OQIjR5EOki5FkebO%2b26WM4BK2TMk4AruDTnyEef5/t5D3heWX4vfPT6l7Lbu6ey37qtstw4Y26wPajvGBxu7xoeqq6N9/Snbp%2b0ZHZY%2bbj4Svt88E3vQ/MLCp41z4U%2bZjy6cND8fPWU%2bHPuo%2bcXYQ8aXo5/Qz0a/MbwSvD5%2b/aajq%2bWdgizLAiJymXPZ4w4Od65I2ZAgZ5JUGiKt8ZD4NgDlOL9IGcIvDvwtUkJEL6Vdrq40fUJQ8FwfvxH4tv6jdeJhgl8Yz8TH79vMzPaZVRuwcbPPxo0BGy/2Z/dWdcDG7QHbYvbZuNtnVr3HrFrPYtWONZJ7jBUK22qxv67YgZPdz4Xzck5FVAoUGfUWB8EcN5AbL0mSE22e5owcMTgfUfSjRLgDqvlFKp8OOVymchjSPden3QhJnIlJqSioiEUoSMOSmbo8ell%2b0nhevWTckL9r/Ey8ZNwoXDFeifPvDLZa0Nmq7EZ7he32mGwtorNpTWfTJYOtxu2OfVvqVpoN/UDjqPTJ3iOBnJzNl7Dsl2V5zokeRXp%2bk5TPU0qnKKIFd5chQnT8UIkfeL2H6Zc/LxBgYXr2Oe2kRQgnEbCWl3N5vczEx/Ur2pPmjwfnjaut88bV7nnj6vAJ47kZmewaHRI0NhU1NglpbBLU2CSusYmpsUlHY5OyxiaLGpuMNDZp8zVLy1uC23YcDFQXW7pVnrSNsiUWZFFFwEVKS50iJpGRSYos/72TEyYiRkjntLYA6UWSaKfTEVw8wNtsnCRJLTNJnMNFduqrSahJCNjJSum0VZmIZ5fOK0%2bZ16sXjGvqBeNaY12ej9y1fGL2n2hsUtfYpKexiaGxyZhkhUTXrKmmsclQY5M%2bB0Rn056xc3vGvsf2LKrdJQ60gmqIWh9P03kyrEbRdGq/RCBJ9MvTfZn0YQeQfr/vzAB8/ZKLP3rkY5X2qDhEKrj6Ir8QAUvrGTCSL5ovxp4wnmuR1M8bV3vnzKcD/OPJaK9XY5PcxlSljGhSJgQ26kuNqj4qrwyn1R3JtJSM4frM0abWlSQD29Tfh3TvrukKOdIk2/MEWo6yIEF7LbvIMUzAhJxyIJ3I/%2bHpEab6QgXVWEKKLZxonwldWr4RvaL/Kvd9/dX8T/Tfx67or%2bTsge3lH5tsTeQ8QLXvJV5AnU27OpvWdTbVdDY1DLaaunf0EYGZ7/ceuOOkt9ZpDx5onUl9uP2xUF7OzgDkQxAnYjKqShFLU/QbNNT0nTSnOl9w1X%2bE1vMUTyBiaAPz8ymWcx2fBIuuyTPlJpm4e9Nn2C/nn9Z/Gha2COGYlY1lmBwXLN%2bCyloJzvw9xip9Zi32mdXrWkzpshHM3lkW11V7jJVnHYAx7FqjQoeNcgM2FsVt1dir7M%2bRLw0vhJJSjE%2bHIh%2bLKYIO0eVdLRCJo5CDpKqqQACIlLVVGonnueMkEUQMIKKfOlz8NubfwK5zrkFhfVFKEE73H/ZcNl6O3Ts%2bLe22Dpf3WkdqO60P9XdZh7p3j0/JH7CO1/aMDnf2j462PmM%2blvim/oPIY8al6Nf0ZyJf1S8vfF1/NnJJvxF6Sn8h9D3t58EXtT/O/0Z7y/fs4BfBC%2ba1%2bP8YcuJO3yfiihGRZZwZwElhANhOdR5zkWbY1R5TdM/L3Jk3bs0ZG0bh9RZXtmbvzhnf8RxvnE5/tng2sqrvtdb0fdpXUo8HDlaPJY6VTkXsoT0D762p7f3Tmu2199se%2b5DteWe77X17u%2b39w%2bo/fK%2bt/tP/2%2bnb/oujl4LfMn8Yvrrld6Gji6d8GTm1oKAap9YUIeFOhDYMMYFNxAGIR39MWeLwWJf4okXEXnbmC2f4ue3w5wIg4dREEQpzKpbmJZAwJScySTmekFVZl1CaFkBsxWEhIkJezkImGQDvfKjoD3Dh3JGSEtFoMRzmEi4GQpF1CQthYX3KmxPmilAsIioi4Mxhfh7QKcphF9FJFOEMRTFN0c/T8zyB1nA7RODwq/iuk%2b0tXzcFwEOLKojI29BWANwyIylQyiBDAwEHCNhDUAoKqlHew/kRma9HRK7v8zaKgLy/t2cnQ1R4Z2kgKjUFFQUR%2bSlzRQaJDz8KOcxBKMuy7CUuiDil%2bR7PBFnHhw06D6V72Jn73SP2u0BwLZhznQ/oiIp1ACxRajUJ5ZDwf1yufRO0r3PCK1HU%2bbuMs15RlJsGbyauwMmuw0%2bZ9qoQwAUqF99mf/v4D3%2bgO6v6e2S/AAAAAElFTkSuQmCC' /%3e%3c/svg%3e\" width=\"1555\" alt=\"foo\" data-srcset=\"/assets/static/hipscript.dark.82a2fbd.4b8b9933739c7717f269ee90e2eb2fff.svg 480w, /assets/static/hipscript.dark.cbab2cf.4b8b9933739c7717f269ee90e2eb2fff.svg 1024w, /assets/static/hipscript.dark.a72e906.4b8b9933739c7717f269ee90e2eb2fff.svg 1555w\" data-sizes=\"(max-width: 1555px) 100vw, 1555px\" data-src=\"/assets/static/hipscript.dark.a72e906.4b8b9933739c7717f269ee90e2eb2fff.svg\"><noscript><img class=\"g-image g-image--lazy g-image--loaded\" src=\"/assets/static/hipscript.dark.a72e906.4b8b9933739c7717f269ee90e2eb2fff.svg\" width=\"1555\" alt=\"foo\"></noscript></p>\n</div>\n<h1 id=\"what-is-hip-cuda\"><a href=\"#what-is-hip-cuda\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>What is HIP? CUDA?</h1>\n<p>CUDA is the name of the API developed by NVIDIA for GPGPU (General-purpose computing on graphics processing units). A CUDA compiler compiles the same C++ file twice: once for the GPU architecture, and once for the host. This way, you can share code between them, and all data types remain the same. CUDA also provides library functions for interacting with the GPU and special syntax for launching CUDA kernels.</p>\n<p>CUDA kernels are written for one thread, but are then executed by many. Several threads (of the programmer's choice) form a \"block\", which can share access to fast on-chip memory. There are then some number of blocks in a \"grid\".</p>\n<p>AMD came along and created HIP, their competitor to CUDA. It has identical syntax and concepts to CUDA—just pretty much does <code class=\"language-text\">sed s/cuda/hip/g</code>! This allows projects like chipStar, which allows HIP code to run on any OpenCL-supported device, to provide a header file that <code class=\"language-text\">#define</code>s CUDA calls into HIP ones.</p>\n<h1 id=\"supported-hipcuda-features\"><a href=\"#supported-hipcuda-features\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Supported HIP/CUDA features</h1>\n<p>This project currently supports a <strong>very basic</strong> subset of HIP and CUDA. However, the supported subset already provides a fair bit of material for learning GPU programming:</p>\n<ul>\n<li>\n<p>Basic kernel launch syntax</p>\n<ul>\n<li>C++ is fully supported, so use generic kernels as you please! The compiler will analyze calls from the CPU side to determine what functions must be generated.</li>\n</ul>\n</li>\n<li>Static and dynamic shared memory</li>\n<li><code class=\"language-text\">__syncthreads</code> (as long as it's in a uniform control flow path, i.e. no early returns or if statements based on <code class=\"language-text\">threadIdx</code>)</li>\n<li><code class=\"language-text\">printf</code> (format string and values are written to a hidden buffer by the GPU, then formatted by the CPU afterwards)</li>\n<li><code class=\"language-text\">assert</code> (although Tint doesn't allow <code class=\"language-text\">__syncthreads</code> afterwards due to <a href=\"https://github.com/gpuweb/gpuweb/issues/3479#issuecomment-1467271026\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">an overzealous control-flow checker</a>)</li>\n<li>\n<p><code class=\"language-text\">hipMalloc</code>, <code class=\"language-text\">hipFree</code>, <code class=\"language-text\">hipMemcpy</code>, <code class=\"language-text\">hipGetSymbolAddress</code>, <code class=\"language-text\">hipMemcpyToSymbol</code>, <code class=\"language-text\">hipLaunchKernel</code>, <code class=\"language-text\">hipLaunchKernelGGL</code>, <code class=\"language-text\">hipGetLastError</code>, <code class=\"language-text\">hipPeekAtLastError</code>, <code class=\"language-text\">hipGetErrorName</code>, <code class=\"language-text\">hipGetErrorString</code></p>\n<ul>\n<li>and corresponding CUDA functions</li>\n</ul>\n</li>\n<li><code class=\"language-text\">__device__</code> and <code class=\"language-text\">__constant__</code> variables (although the latter are treated the same as the former, i.e. read-write)</li>\n</ul>\n<h2 id=\"unsupported-features\"><a href=\"#unsupported-features\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Unsupported Features</h2>\n<ul>\n<li>\n<p>any functions not listed above</p>\n<ul>\n<li>streams</li>\n<li>graphs</li>\n<li>managed/asynchronous memory transfers</li>\n</ul>\n</li>\n<li>64-bit floating point (WebGPU limitation) and 16-bit floating point (Tint limitation) numbers</li>\n<li>integers other than 32-bit signed and unsigned integers (WebGPU limitation)</li>\n<li>\n<p>many things with pointers:</p>\n<ul>\n<li>passing a pointer to a kernel not directly as a parameter (e.g. in a struct)</li>\n<li>\n<p><strong>pointer manipulation on the CPU side</strong>: note this means that you cannot pass an offset to <code class=\"language-text\">hipMemcpy</code> or a kernel</p>\n<ul>\n<li>WebGPU would allow a 128-byte aligned offset passed to a kernel. However, I decided not to implement that because of the limited 32-bit address space of WASM.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>warp intrinsics (should be possible, although currently requires experimental Chrome flags)</li>\n<li>dynamic parallelism (could be polyfilled by converting calls to writes in a buffer, then launching kernels from the CPU)</li>\n<li>any GPU libraries: cuDNN, cuBLAS, cuRAND, ...</li>\n<li>Cooperative Groups</li>\n<li>Inline PTX (<a href=\"https://github.com/CHIP-SPV/chipStar/discussions/904#discussioncomment-10255598\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">although it has been done before</a>)</li>\n</ul>\n<h1 id=\"how-its-built\"><a href=\"#how-its-built\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>How it's built</h1>\n<p>Using LLVM compiled to WebAssembly, the input source code is first passed through Clang, which already understands HIP and CUDA. These languages are compiled in two passes—for the GPU using SPIR-V and for the CPU using WebAssembly. These use WebAssembly headers, meaning all types are the same size. Then, the GPU side code is fed through chipStar, a HIP-to-OpenCL translator. I keep its output as LLVM bitcode to immediately pass through Clspv, converting it to a Vulkan shader. Finally, Google's Tint from the Dawn project translates it to WGSL. A WebAssembly implementation of the HIP API then coordinates kernel launches.</p>\n<p>I aimed to keep file size in mind. To package as large of a project LLVM is, I wanted to make sure I wasn't duplicating any code—for example, the WASM backend code shouldn't exist separately in the compiler and linker. This is traditionally done with dynamic linking, which isn't supported by Wasmer (it is by Emscripten, but by going through a JS intermediate: slow). Thankfully, LLVM has an option just for this case: <code class=\"language-text\">LLVM_TOOL_LLVM_DRIVER_BUILD</code>. By setting this flag, LLVM creates a single entrypoint that statically links to every executable. This way, you can just pass the desired tool as arg0 or arg1, like <code class=\"language-text\">llvm clang++ file.cpp</code>.</p>\n<p>I then bundled the chipStar LLVM passes in the LLVM source code. I added a command-line flag that allows Clang to run the passes. Typically they're run with <code class=\"language-text\">opt</code>, but that isn't compatible with the driver. Clspv and SPIRV-Tools were added as <code class=\"language-text\">LLVM_EXTERNAL_PROJECTS</code> to be additionally integrated in the single tool.</p>\n<h1 id=\"issues-i-encountered\"><a href=\"#issues-i-encountered\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Issues I encountered</h1>\n<h2 id=\"wasmer-runtime-workarounds\"><a href=\"#wasmer-runtime-workarounds\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Wasmer Runtime Workarounds</h2>\n<p>I compiled LLVM using the WASIX toolchain, because it offers much needed functions not available in vanilla WASI, and Emscripten doesn't feel great for porting traditional command-line applications. However, the Wasmer SDK is the only implementation of the WASIX specification, and the JS version has some bugs. <a href=\"https://github.com/wasmerio/wasmer-js/issues/407\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">You can't load a WASM file directly</a>, loading their \"webc\" container directly just failed with a generic <code class=\"language-text\">Unreachable</code> error, and the recommended Wasmer CDN doesn't compress files—even when a 5x compression ratio is possible. This large file size then causes Chrome to not cache anything at all! So, I set the \"API endpoint\" of the CDN to a simple <code class=\"language-text\">file:</code> URI that points to a <code class=\"language-text\">blob:</code> URI for the actual WASM file. On the page load, I handle downloading and caching the binary manually.</p>\n<p>Then, I was running into issues where I'd get another generic <code class=\"language-text\">Unreachable</code> after launching more than a couple programs. I worked around this by just spawning new Web Workers and completely re-loading the SDK in each. Very thankfully, it seems like Chrome caches <code class=\"language-text\">WebAssembly.compile</code> calls with the same binary input so there isn't too much of a performance penalty.</p>\n<p>I couldn't debug these issues because <a href=\"https://github.com/wasmerio/wasmer-js/issues/437\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">the Wasmer SDK source is currently unable to be built</a> and the package on NPM doesn't ship with debug symbols.</p>\n<h2 id=\"compressed-data-on-cloudflare-r2\"><a href=\"#compressed-data-on-cloudflare-r2\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Compressed Data on Cloudflare R2</h2>\n<p>GZip compression brought by LLVM bundle from 75MB to 21MB, and Brotli further to 15MB. I decided to use Brotli because of these savings, and it's supported on all modern browsers. I decided to use Cloudflare R2 as my storage provider, on which <a href=\"https://alexi.sh/blog/2023/03/using-r2-to-store-and-serve-compressed-content/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">others have had success uploading pre-compressed data to</a> since it won't compress to Brotli for you. However, I was encountering issues with the upload step, since rclone was detecting an incorrectly-sized upload. Turns out, you need to specify <code class=\"language-text\">Cache-Control: no-transform</code>. That has the bonus of correctly supporting custom domains with R2 (strongly encouraged for production), since it tells Cloudflare not to uncompress the data, bypassing the entire purpose of doing this.</p>\n<div class=\"gridsome-highlight\" data-language=\"text\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-text line-numbers\"><code class=\"language-text\">rclone copyto --progress --header-upload \"Content-Type: application/octet-stream\" --header-upload \"Content-Encoding: br\" --header-upload \"Cache-Control: no-transform\" $file $connection:$bucket/$serverpath</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>Before I discovered that, I used gdb to set a breakpoint on <code class=\"language-text\">github.com/rclone/rclone/fs/operations.(*copy).removeFailedCopy</code> to stop deleting the (sucessfully, but it didn't know that) uploaded file.</p>\n","path":"/blog/2025/01/07/hip-script/","headings":[{"depth":1,"value":"What is HIP? CUDA?","anchor":"#what-is-hip-cuda"},{"depth":1,"value":"Supported HIP/CUDA features","anchor":"#supported-hipcuda-features"},{"depth":2,"value":"Unsupported Features","anchor":"#unsupported-features"},{"depth":1,"value":"How it's built","anchor":"#how-its-built"},{"depth":1,"value":"Issues I encountered","anchor":"#issues-i-encountered"},{"depth":2,"value":"Wasmer Runtime Workarounds","anchor":"#wasmer-runtime-workarounds"},{"depth":2,"value":"Compressed Data on Cloudflare R2","anchor":"#compressed-data-on-cloudflare-r2"}],"date":"January 7, 2025","rawDate":"2025-01-07T00:00:00.000Z","updated":null,"rawUpdated":null,"timeToRead":5}},"context":{}}